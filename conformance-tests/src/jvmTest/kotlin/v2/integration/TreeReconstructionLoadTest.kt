package v2.integration

import kotlinx.coroutines.CoroutineScope
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.Job
import kotlinx.coroutines.channels.Channel
import kotlinx.coroutines.launch
import kotlinx.coroutines.runBlocking
import org.junit.jupiter.api.Assertions.assertTrue
import org.junit.jupiter.api.Disabled
import org.junit.jupiter.api.Test
import v2.FuncDecl
import v2.Lexer
import v2.Parser
import v2.TransformDecl
import v2.ir.ToIR
import v2.std.DefaultSharedStore
import v2.std.SharedResourceKind
import v2.std.StdLib
import v2.vm.Compiler
import v2.vm.VM
import java.util.UUID
import kotlin.math.max
import kotlin.math.min
import kotlin.random.Random
import kotlin.system.measureTimeMillis

@Disabled("Load/perf test â€” run manually; generates heavy workload")
class TreeReconstructionLoadTest {

    data class Edge(val treeId: String, val fromId: String, val toId: String)

    @Test
    fun `measure SharedStore throughput in VM for tree reconstruction`() {
        val totalTrees = System.getProperty("LOAD_TREES")?.toIntOrNull() ?: 1000
        val minDepth = System.getProperty("LOAD_MIN_DEPTH")?.toIntOrNull() ?: 5
        val maxDepth = System.getProperty("LOAD_MAX_DEPTH")?.toIntOrNull() ?: 10
        val minBranch = System.getProperty("LOAD_MIN_BRANCH")?.toIntOrNull() ?: 5
        val maxBranch = System.getProperty("LOAD_MAX_BRANCH")?.toIntOrNull() ?: 10
        val capEdges = System.getProperty("LOAD_CAP_EDGES")?.toIntOrNull() ?: 250_000
        val parallelConfigs = intArrayOf(1, 4, 16, 64)

        // Compile tiny DSL to bytecode; VM executes per edge
        val bytecodeVm = compileToVM()

        // Generate workload once (shuffled), then reuse for each run on a fresh store
        val workload = generateWorkload(
            totalTrees = totalTrees,
            minDepth = minDepth,
            maxDepth = maxDepth,
            minBranch = minBranch,
            maxBranch = maxBranch,
            capEdges = capEdges,
            seed = 42
        )

        println("LoadTest - trees=$totalTrees depth=${minDepth}..${maxDepth} branch=${minBranch}..${maxBranch} edges=${workload.size}")

        for (p in parallelConfigs) {
            val shared = DefaultSharedStore().apply { addResource("nodeParents", SharedResourceKind.SINGLE) }
            val elapsedMs = measureTimeMillis {
                runPipelineWithParallelism(
                    edges = workload,
                    parallelism = p,
                    vm = bytecodeVm.vm,
                    bytecode = bytecodeVm.bytecode,
                    shared = shared
                )
            }
            val eps = if (elapsedMs > 0) (workload.size * 1000L) / elapsedMs else Long.MAX_VALUE
            println("parallel=$p took=${elapsedMs}ms throughput=${eps} edges/sec")
            assertTrue(elapsedMs < 60_000, "Single config should finish within 60s in CI env")
        }
    }

    private data class VMProgram(val vm: VM, val bytecode: v2.vm.Bytecode)

    private fun compileToVM(): VMProgram {
        val program = """
            TRANSFORM T { stream } {
                LET msg = row;
                // Keep VM work non-trivial
                LET a = msg.treeId;
                OUTPUT { ok: true };
            }
        """.trimIndent()

        val tokens = Lexer(program).lex()
        val prog = Parser(tokens, program).parse()
        val funcs = prog.decls.filterIsInstance<FuncDecl>().associateBy { it.name }
        val hostFns = StdLib.fns
        val transform = prog.decls.filterIsInstance<TransformDecl>().single()
        val ir = ToIR(funcs, hostFns).compile(transform.body.statements)
        val compiler = Compiler(funcs, hostFns)
        val bytecode = compiler.compile(ir)
        val vm = VM(hostFns, funcs)
        return VMProgram(vm, bytecode)
    }

    private fun runPipelineWithParallelism(
        edges: List<Edge>,
        parallelism: Int,
        vm: VM,
        bytecode: v2.vm.Bytecode,
        shared: DefaultSharedStore,
    ) = runBlocking {
        val channel = Channel<Edge>(capacity = 4096)
        val producer = launch(Dispatchers.Default) {
            for (e in edges) channel.send(e)
            channel.close()
        }
        val workers = mutableListOf<Job>()
        var idx = 0
        while (idx < parallelism) {
            val job = launch(Dispatchers.Default) {
                for (e in channel) processEdge(e, vm, bytecode, shared)
            }
            workers.add(job)
            idx += 1
        }
        producer.join()
        workers.forEach { it.join() }
    }

    private fun processEdge(
        e: Edge,
        vm: VM,
        bytecode: v2.vm.Bytecode,
        shared: DefaultSharedStore,
    ) {
        val level: Int = if (e.fromId == "root") {
            1
        } else {
            val parentKey = keyOf(e.treeId, e.fromId)
            val parentInfo = runBlocking { shared.await("nodeParents", parentKey) } as Map<*, *>
            val parentLevel = parentInfo["level"] as Int
            parentLevel + 1
        }

        val env = mutableMapOf<String, Any?>(
            "row" to mapOf(
                "treeId" to e.treeId,
                "fromId" to e.fromId,
                "toId" to e.toId
            )
        )
        vm.execute(bytecode, env)

        val nodeKey = keyOf(e.treeId, e.toId)
        val nodeInfo = mapOf(
            "nodeId" to e.toId,
            "level" to level,
            "treeId" to e.treeId,
            "parentId" to e.fromId
        )
        runBlocking { shared.setOnce("nodeParents", nodeKey, nodeInfo) }
    }

    private fun keyOf(treeId: String, nodeId: String): String {
        return StringBuilder(treeId.length + 1 + nodeId.length)
            .append(treeId).append(':').append(nodeId).toString()
    }

    private fun generateWorkload(
        totalTrees: Int,
        minDepth: Int,
        maxDepth: Int,
        minBranch: Int,
        maxBranch: Int,
        capEdges: Int,
        seed: Int,
    ): List<Edge> {
        val rnd = Random(seed)
        val out = ArrayList<Edge>(min(capEdges, totalTrees * 32))
        var produced = 0
        var t = 0
        while (t < totalTrees && produced < capEdges) {
            val treeId = UUID.randomUUID().toString()
            val depth = clamp(minDepth + rnd.nextInt(max(1, maxDepth - minDepth + 1)), 1, 32)
            val branch = clamp(minBranch + rnd.nextInt(max(1, maxBranch - minBranch + 1)), 1, 32)
            produced += generateTreeEdges(treeId, depth, branch, capEdges - produced, out, rnd)
            t += 1
        }
        out.shuffle(rnd)
        return out
    }

    private fun clamp(v: Int, lo: Int, hi: Int): Int {
        return max(lo, min(v, hi))
    }

    private fun generateTreeEdges(
        treeId: String,
        maxDepth: Int,
        branching: Int,
        remainingBudget: Int,
        out: MutableList<Edge>,
        rnd: Random,
    ): Int {
        if (remainingBudget <= 0) return 0
        var produced = 0
        var nextNodeIdx = 1

        val queueIds = ArrayDeque<String>()
        val queueDepth = ArrayDeque<Int>()

        val rootId = "n${nextNodeIdx++}"
        out.add(Edge(treeId, "root", rootId))
        produced += 1
        if (produced >= remainingBudget) return produced

        queueIds.add(rootId)
        queueDepth.add(1)

        while (queueIds.isNotEmpty() && produced < remainingBudget) {
            val parentId = queueIds.removeFirst()
            val depth = queueDepth.removeFirst()
            if (depth >= maxDepth) continue
            val children = 1 + rnd.nextInt(max(1, branching))
            var i = 0
            while (i < children && produced < remainingBudget) {
                val childId = "n${nextNodeIdx++}"
                out.add(Edge(treeId, parentId, childId))
                produced += 1
                queueIds.add(childId)
                queueDepth.add(depth + 1)
                i += 1
            }
        }
        return produced
    }
}

